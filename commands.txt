
exp_1e1_mem_mldg_after_plate

CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GS --network MemDeeplabv3plus --lamb_cpt 0.1 --memory --lamb_sep 0.1 --name exp_1e1_mem_mldg_after_plate --mem_after_update --sche lrplate &> exp_1e1_mem_mldg_after_plate.out &

exp_1e1_mem_mldg_after

CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network MemDeeplabv3plus --lamb_cpt 0.1 --memory --lamb_sep 0.1 --name exp_1e1_mem_mldg_after --mem_after_update &> exp_1e1_mem_mldg_after.out &


exp_1e1_mem_mldg

CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network MemDeeplabv3plus --lamb_cpt 0.1 --memory --lamb_sep 0.1 --name exp_1e1_mem_mldg &> exp_1e1_mem_mldg_after.out &


exp_1e1_mem_agg
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GS --network MemDeeplabv3plus --lamb_cpt 0.1 --memory --lamb_sep 0.1 --train-num 10000000 --name exp_1e1_mem_agg &> exp_1e1_mem_agg.out &



exp_nomem_mldg
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network MemDeeplabv3plus --name exp_nomem_mldg &> exp_nomem_mldg.out &

exp_nomem_mldg_cosine
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network MemDeeplabv3plus --name exp_nomem_mldg_cosine --sche cosine &> exp_nomem_mldg_cosine.out &

exp_nomem_agg_plate
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network MemDeeplabv3plus --name exp_nomem_agg_plate --train-num 10000000 --sche lrplate &> exp_nomem_agg_plate.out &


exp_nomem_agg
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network MemDeeplabv3plus --name exp_nomem_agg --train-num 10000000 &> exp_nomem_agg.out &

exp_1e2_mem_mldg_after_cosine
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GS --network MemDeeplabv3plus --lamb_cpt 0.1 --memory --lamb_sep 0.2 --name exp_1e2_mem_mldg_after_cosine --mem_after_update --sche cosine &> exp_1e2_mem_mldg_after_cosine.out &

exp_mem_agg_cosine
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network MemDeeplabv3plus --name exp_mem_agg_cosine --train-num 10000000 --memory --sche cosine &> exp_mem_agg_cosine.out &

exp_nomem_agg_cosine
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network MemDeeplabv3plus --name exp_nomem_agg_cosine --train-num 10000000 --sche cosine &> exp_nomem_agg_cosine.out &

exp_1e2_supmem_mldg_after_lrplate
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GS --network MemDeeplabv3plus --lamb_cpt 0.1 --memory --supervised_mem --lamb_sep 0.2 --name exp_1e2_supmem_mldg_after_lrplate --mem_after_update --sche lrplate &> exp_1e2_supmem_mldg_after_lrplate.out &


exp_mldg_supmem_sep1_tempe-1_nooutseploss_no1x1write
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory --supervised_mem --lamb_sep 1 --name exp_mldg_supmem_sep1_tempe-1_nooutseploss_no1x1write --sche lrplate --no_outer_memloss &> exp_mldg_supmem_sep1_tempe-1_nooutseploss_no1x1write.out &

exp_mldg_supmem_sep1_tempe-1_nooutseploss_1x1write
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory --supervised_mem --lamb_sep 1 --name exp_mldg_supmem_sep1_tempe-1_nooutseploss_1x1write --sche lrplate --no_outer_memloss --add1by1 &> exp_mldg_supmem_sep1_tempe-1_nooutseploss_1x1write.out &


exp_mldg_supmem_sep1_temp1_nooutseploss_1x1write
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory --supervised_mem --lamb_sep 1 --name exp_mldg_supmem_sep1_temp1_nooutseploss_1x1write --sche lrplate --no_outer_memloss --add1by1 &> exp_mldg_supmem_sep1_temp1_nooutseploss_1x1write.out &


exp_mldg_supmem_lr1e-2_sep1_temp1_nooutseploss_1x1write_valtotrain_newtransform
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory --supervised_mem --lamb_sep 1 --name exp_mldg_supmem_lr1e-2_sep1_temp1_nooutseploss_1x1write_valtotrain_newtransform --sche lrplate --no_outer_memloss --add1by1 --outer-lr 0.01 &> exp_mldg_supmem_lr1e-2_sep1_temp1_nooutseploss_1x1write_valtotrain_newtransform.out &

exp_mldg_supmem_sep1_temp1_nooutseploss_1x1write_newtransform_momentum1e-8
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory --supervised_mem --lamb_sep 1 --temperature 1 --name exp_mldg_supmem_sep1_temp1_nooutseploss_1x1write_newtransform_momentum1e-8 --sche lrplate --no_outer_memloss --add1by1 --momentum 0.8 &> exp_mldg_supmem_sep1_temp1_nooutseploss_1x1write_newtransform_momentum1e-8.out &

exp_mldg_supmem_sep1_temp1_nooutseploss_1x1write_newtransform_momentum1e-2
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory --supervised_mem --lamb_sep 1 --temperature 1 --name exp_mldg_supmem_sep1_temp1_nooutseploss_1x1write_newtransform_momentum1e-2 --sche lrplate --no_outer_memloss --add1by1 --momentum 0.2 &> exp_mldg_supmem_sep1_temp1_nooutseploss_1x1write_newtransform_momentum1e-2.out &


exp_mldg_supmem_sep1_temp1_nooutseploss_1x1write_newtransform_momentum1e-5
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory --supervised_mem --lamb_sep 1 --temperature 1 --name exp_mldg_supmem_sep1_temp1_nooutseploss_1x1write_newtransform_momentum1e-5 --sche lrplate --no_outer_memloss --add1by1 --momentum 0.5 &> exp_mldg_supmem_sep1_temp1_nooutseploss_1x1write_newtransform_momentum1e-5.out &


exp_mlmdg_clsloss
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory sup --name exp_mlmdg_clsloss --sche lrplate --add1by1 --clsfy_loss &> exp_mlmdg_clsloss.out &

exp_mlmdg_hideandseek_gumbelread
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory sup --name exp_mlmdg_hideandseek_gumbelread --sche lrplate --add1by1 --hideandseek --gumbel_read &> exp_mlmdg_hideandseek_gumbelread.out &

exp_mlmdg_clsloss_hideandseek
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory sup --name exp_mlmdg_clsloss_hideandseek --sche lrplate --add1by1 --clsfy_loss --hideandseek &> exp_mlmdg_clsloss_hideandseek.out &

exp_mlmdg_clsloss_gumbelread
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory sup --name exp_mlmdg_clsloss_gumbelread --sche lrplate --add1by1 --clsfy_loss --gumbel_read &> exp_mlmdg_clsloss_gumbelread.out &

exp_mlmdg_clsloss_hideandseek_gumbelread
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory sup --name exp_mlmdg_clsloss_hideandseek_gumbelread --sche lrplate --add1by1 --clsfy_loss --hideandseek --gumbel_read &> exp_mlmdg_clsloss_hideandseek_gumbelread.out &


exp_mlmdg_clsloss_hideandseek_gumbelread_stride8
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory sup --name exp_mlmdg_clsloss_hideandseek_gumbelread_stride8 --sche lrplate --add1by1 --clsfy_loss --hideandseek --gumbel_read --output_stride 8 &> exp_mlmdg_clsloss_hideandseek_gumbelread_stride8.out &


---------------------------------new version command line--------------------------
exp_mldg_Dlv3r50
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GS --network Deeplabv3plus_Memsup --name exp_mldg_Dlv3r50 --backbone resnet50 --sche lrplate &> exp_mldg_Dlv3r50.out &

exp_agg_Dlv3r50
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network Deeplabv3plus_Memsup --name exp_agg_Dlv3r50 --backbone resnet50 --sche lrplate --train-num 10000000 &> exp_agg_Dlv3r50.out &

exp_mlmdg_clsloss_gumbelread_fixed
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory --name exp_mlmdg_clsloss_gumbelread_fixed --sche lrplate --add1by1 --clsfy_loss --gumbel_read &> exp_mlmdg_clsloss_gumbelread_fixed.out &

exp_mlmdg_clsloss_gumbelread_singleG_fixed
CUDA_VISIBLE_DEVICES=0 nohup python train.py --source GG --network Deeplabv3plus_Memsup --memory --name exp_mlmdg_clsloss_gumbelread_singleG_fixed --sche lrplate --add1by1 --clsfy_loss --gumbel_read &> exp_mlmdg_clsloss_gumbelread_singleG_fixed.out &


exp_agg_singleG_fixed
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GG --network Deeplabv3plus_Memsup --name exp_agg_singleG_fixed --sche lrplate --train-num 10000000 &> exp_agg_singleG_fixed.out &


# 여기서부터 171 두개
exp_mlmdg_clsloss_gumbelread_hideandseek_fixed
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GS --network Deeplabv3plus_Memsup --memory --name exp_mlmdg_clsloss_gumbelread_hideandseek_fixed --sche lrplate --add1by1 --clsfy_loss --gumbel_read --hideandseek &> exp_mlmdg_clsloss_gumbelread_hideandseek_fixed.out &

exp_mldg_singleG_fixed
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GG --network Deeplabv3plus_Memsup --name exp_mldg_singleG_fixed --sche lrplate &> exp_mldg_singleG_fixed.out &





exp_mlmdg_FCN8s_resnet50_clsloss_gumbelread_G
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GG --network FCN_Memsup --memory --name exp_mlmdg_FCN8s_resnet50_clsloss_gumbelread_G --sche lrplate --add1by1 --clsfy_loss --gumbel_read --reading_module &> exp_mlmdg_FCN8s_resnet50_clsloss_gumbelread_G.out &

exp_mldg_FCN8s_resnet50_G
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GG --network FCN_Memsup --name exp_mldg_FCN8s_resnet50_G --sche lrplate --reading_module &> exp_mldg_FCN8s_resnet50_G.out &

exp_agg_FCN8s_resnet50_G
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GG --network FCN_Memsup --name exp_agg_FCN8s_resnet50_G --sche lrplate --train-num 10000000 --reading_module &> exp_agg_FCN8s_resnet50_G.out &


## resnet101 FCN8s mlmdg no reading module
exp_mlmdg_FCN8s_resnet101_clsloss_gumbelread_G_noreadingmodule
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GG --network FCN_Memsup --memory --name exp_mlmdg_FCN8s_resnet101_clsloss_gumbelread_G_noreadingmodule --sche lrplate --add1by1 --clsfy_loss --gumbel_read &> exp_mlmdg_FCN8s_resnet101_clsloss_gumbelread_G_noreadingmodule.out &


# 여기서부터 두개.
exp_mlmdg_FCN8s_resnet50_clsloss_gumbelread_GS
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GS --network FCN_Memsup --memory --name exp_mlmdg_FCN8s_resnet50_clsloss_gumbelread_GS --sche lrplate --add1by1 --clsfy_loss --gumbel_read --reading_module &> exp_mlmdg_FCN8s_resnet50_clsloss_gumbelread_GS.out &

exp_mlmdg_FCN8s_resnet101_clsloss_gumbelread_G
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source GG --network FCN_Memsup --memory --name exp_mlmdg_FCN8s_resnet101_clsloss_gumbelread_G --backbone resnet101 --sche lrplate --add1by1 --clsfy_loss --gumbel_read --reading_module &> exp_mlmdg_FCN8s_resnet101_clsloss_gumbelread_G.out &



exp_mlmdg_FCN8s_resnet50_clsloss_gumbelread_S
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source SS --network FCN_Memsup --memory --name exp_mlmdg_FCN8s_resnet50_clsloss_gumbelread_S --sche lrplate --add1by1 --clsfy_loss --gumbel_read --reading_module &> exp_mlmdg_FCN8s_resnet50_clsloss_gumbelread_S.out &

exp_mlmdg_FCN8s_resnet101_clsloss_gumbelread_S
CUDA_VISIBLE_DEVICES=1 nohup python train.py --source SS --network FCN_Memsup --memory --name exp_mlmdg_FCN8s_resnet101_clsloss_gumbelread_S --backbone resnet101 --sche lrplate --add1by1 --clsfy_loss --gumbel_read --reading_module &> exp_mlmdg_FCN8s_resnet101_clsloss_gumbelread_S.out &


